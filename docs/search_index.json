[["tidy-data.html", "6 Tidy Data 6.1 Data entry 6.2 Tidy data and data wrangling 6.3 The dataset 6.4 Reading data 6.5 A quick aside on data types 6.6 A quick aside on data structures", " 6 Tidy Data This section is a demonstration of some of the Tidyverse tools for wrangling and tidying your data, but first you need to get your data into a digital format… 6.1 Data entry Before we start, I should highlight that one very good way of reducing errors in data entry and improving quality assurance and quality control (QA/QC) is to make use of various forms of data validation like drop down lists and conditional formatting. These can be used to limit data types (i.e. avoids you entering text into a numeric column or vice versa), or limiting the range of values entered (e.g. 0 to 100 for percentages), or just highlighting values that are possible, but rare, and should be double-checked, like 100m tall trees. Unit errors are incredibly common in ecological data entry, especially for things like plant height where you may be measuring 20cm tall grasses and 20m tall trees!!! Drop down lists really come into their own when you’re working with lots of different Latin species names etc. Typos, spelling errors and synonyms can take weeks of work to fix! Restricting the names to a drop-down list from a known published taxonomic resource really makes a huge difference! Here’s an example from a vegetation plot survey I ran. If you go to the PlotTemplate sheet, you’ll see that the first two columns Plot_Quadrat and AcceptedSpecies are drop-down lists that reference the SiteData and AcceptedSpecies spreadsheets respectively. These prevent you from entering species data without having collected the site data first (it’s easy to forget if you’re doing lots of sites) and then limits the names you can use in turn. I’m not going to go into how to do data validation in spreadsheets, but here are links for: Microsoft Excel Google Sheets I’m sure there are plenty of other online resources too. 6.2 Tidy data and data wrangling As you know from the readings for the course, there are many reasons why you should keep your data in tidy format (Wickham 2014). Unfortunately, as my spreadsheet above demonstrates, it’s not always convenient to enter your data in tidy format, so you inevitably end out needing to do post-entry data formatting. A major problem here is that doing the reformatting manually creates opportunities for introducing errors. This is where it’s a major advantage if you know how to wrangle your data in a coding language like R or Python. This is not to say that coded data wrangling cannot introduce errors!!! You should always do sanity checks!!! But I’d suspect that most of the errors you can make with code will be very obvious, because the outcome is usually spectacularly different to the input. The rest of this section provides a demonstration of some of the functionality of the tidyverse set of R packages, and some of the more common data wrangling errors made in R. 6.3 The dataset This tutorial relies on data provided as supplementary material for the paper Slingsby et al. 2017. Intensifying postfire weather and biological invasion drive species loss in a Mediterranean-type biodiversity hotspot. Proceedings of the National Academy of Sciences. http://dx.doi.org/10.1073/pnas.1619014114. The data can be downloaded and unzipped from here. 6.4 Reading data R has a number of different packages to read in data, and there’s even a few that work with different tabular data types just within the tidyverse. These include: readr for text files readxl for Microsoft Excel files (.xls or .xlsx) googlesheets4 for reading data directly from a Google Sheet There’s others too that can scrape data from web pages, interact with web APIs, or query local or online databases. Fortunately, within the tidyverse, similar syntax can be used across most data import packages. Check out the cheat sheet. Let’s start with readr. First, we may want to know what files are in our data folder, which we can do with the base function list.files(). NOTE: you need to replace the working directory folder path with wherever you put the data on your computer. # get list of files in the folder (change to your own) list.files(&quot;data/Slingsby_TaylorPlots&quot;) ## [1] &quot;Dataset S1.xlsx&quot; ## [2] &quot;Dataset S2_Weather_Data_Analysis.Rmd&quot; ## [3] &quot;Dataset S3_Vegetation_Analysis.Rmd&quot; ## [4] &quot;Dataset S4_Community_Climate_Shift_Analysis.Rmd&quot; ## [5] &quot;Dataset_S2_Weather_Data_Analysis.pdf&quot; ## [6] &quot;Dataset_S3_Vegetation_Analysis.pdf&quot; ## [7] &quot;Dataset_S4_Community_Climate_Shift_Analysis.pdf&quot; ## [8] &quot;Dataset_S5_RMarkdown_Output.pdf&quot; ## [9] &quot;enviroment.csv&quot; ## [10] &quot;excluded_spp.csv&quot; ## [11] &quot;fires.csv&quot; ## [12] &quot;postfireweather.csv&quot; ## [13] &quot;README.md&quot; ## [14] &quot;speciesclimatedata.csv&quot; ## [15] &quot;traits.csv&quot; ## [16] &quot;veg1966.csv&quot; ## [17] &quot;veg1996.csv&quot; ## [18] &quot;veg2010.csv&quot; ## [19] &quot;weather.csv&quot; So we have: a bunch of RMarkdown files (.Rmd) that perform the analyses used in the paper. The .Rmd files output the .pdf documents of the same name. We can ignore all of these. a bunch of text files in comma separated value format (.csv). These are essentially spreadsheets, where the columns are denoted by commas. one MicroSoft Excel (.xlsx) file. Let’s read in a .csv file # get 1966 vegetation data veg66 &lt;- read_csv(&quot;data/Slingsby_TaylorPlots/veg1966.csv&quot;) ## New names: ## * `` -&gt; ...1 ## Rows: 81 Columns: 428 ## ── Column specification ────────────────────────────────────────────────── ## Delimiter: &quot;,&quot; ## chr (1): ...1 ## dbl (427): Adenandra uniflora, Adenandra villosa, Adenocline pauciflor... ## ## ℹ Use `spec()` to retrieve the full column specification for this data. ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message. # print the first few lines (note this is a tibble) veg66 ## # A tibble: 81 × 428 ## ...1 `Adenandra uniflora` `Adenandra villosa` `Adenocline pauciflora` ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 CP_1 0 7 0 ## 2 CP_10 0 0 0 ## 3 CP_100 0 7 0 ## 4 CP_12 0 0 0 ## 5 CP_13 0 0 0 ## 6 CP_14 0 0 0 ## 7 CP_15 0 7 0 ## 8 CP_16 0 0 0 ## 9 CP_17 0 0 0 ## 10 CP_18 0 0 0 ## # … with 71 more rows, and 424 more variables: ## # `Agathosma ciliaris` &lt;dbl&gt;, `Agathosma hookeri` &lt;dbl&gt;, ## # `Agathosma imbricata` &lt;dbl&gt;, `Agathosma lanceolata` &lt;dbl&gt;, ## # `Agathosma serpyllacea` &lt;dbl&gt;, `Aizoon paniculatum` &lt;dbl&gt;, ## # `Amphithalea ericifolia` &lt;dbl&gt;, `Anaxeton laeve` &lt;dbl&gt;, ## # `Anemone knowltonia` &lt;dbl&gt;, `Anthochortus laxiflorus` &lt;dbl&gt;, ## # `Anthospermum aethiopicum` &lt;dbl&gt;, `Anthospermum bergianum` &lt;dbl&gt;, … You’ll note &lt;chr&gt; and &lt;dbl&gt; in the output. These indicate that the data types (or classes) for those columns are “character” and “double” respectively… 6.5 A quick aside on data types R’s basic data types are character, integer, numeric (or double, they are synonymous), complex, and logical. integer is for whole numbers (i.e. no decimals) numeric or double (double precision floating point numbers) are real numbers - i.e. they include decimal places. For reasons I won’t explain, storing data as real numbers takes up far more memory than integers. Obviously, lots of numbers we work with are real numbers, so we need to be able to work with them. Interestingly, large data storage and transmission projects (e.g. satellite remote sensing) often do tricks like multiply values by some constant so that all data stored are integers. You need to correct by the constant during your analysis to get values in the actual unit of measurement. logical is the outcome of a conditional statement (i.e. values can only be TRUE or FALSE) character is for letters, words, sentences or mixed strings (i.e. letters and digits) factor is a set of levels (often treatments) that you’d use in an analysis. They are very useful, but they are also VERY likely to trip you up at some stage (I’ll explain why in a minute)!!! factors are essentially numerical codings of character data in some order. Using mumerical coding is useful, because you can order your levels in an analysis - e.g. Treatment A, Treatment B, Control, etc. They are also useful, because they can store data efficiently. For example, if your analysis has thousands of data points, it uses much less memory to recode the treatments above as 1, 2, 3, etc and just store one copy of the levels (what we call the labels in a factors). logical is actually just a special case of factor data where FALSE = 0 and TRUE = 1. That said, R treats logical in specific ways that can’t be done with true factors and vice versa, so forget said that. Here’re some code examples to try to drive this home, using the built in vector `letters letters ## [1] &quot;a&quot; &quot;b&quot; &quot;c&quot; &quot;d&quot; &quot;e&quot; &quot;f&quot; &quot;g&quot; &quot;h&quot; &quot;i&quot; &quot;j&quot; &quot;k&quot; &quot;l&quot; &quot;m&quot; &quot;n&quot; &quot;o&quot; &quot;p&quot; &quot;q&quot; ## [18] &quot;r&quot; &quot;s&quot; &quot;t&quot; &quot;u&quot; &quot;v&quot; &quot;w&quot; &quot;x&quot; &quot;y&quot; &quot;z&quot; You can check the class of data using the function class() class(letters) ## [1] &quot;character&quot; And typically convert (or coerce) between classes using as. followed by the class you want, e.g. as.factor(letters) ## [1] a b c d e f g h i j k l m n o p q r s t u v w x y z ## Levels: a b c d e f g h i j k l m n o p q r s t u v w x y z Here it shows us that we have a factor with 26 values with 26 unique levels. You wouldn’t really use a factor class if all values are unique though. Here’s a better example. as.factor(rep(letters[1:3], 8)) ## [1] a b c a b c a b c a b c a b c a b c a b c a b c ## Levels: a b c And to prove that the factor represents the levels as a set of numbers: as.numeric(as.factor(rep(letters[1:3], 8))) ## [1] 1 2 3 1 2 3 1 2 3 1 2 3 1 2 3 1 2 3 1 2 3 1 2 3 Note that this doesn’t work if we try to coerce the the letters to numbers without making them a factor first: as.numeric(rep(letters[1:3], 8)) ## Warning: NAs introduced by coercion ## [1] NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA ## [24] NA Here’s how factors will catch you out, sooner or later… As I said earlier, storing data as a factor can be less memory intensive. R takes advantage of this in that some functions (especially when reading in data) try to identify the most sensible data type and store it in R’s memory as such. So for example, if all the valuesin a column of a table are whole numbers, R will read it in as class integer, which requires less memory than class numeric (or double). By the same token, if the column is text and some values are repeated, R will often make it class factor. This is great, but it can catch you out as follows. If a column of numbers has any text in it, R will make the whole column class character. If many of the values are repeated, it may even make it class factor for efficiency. This happens a lot!, especially if someone makes an error and types in an O instead of a 0, or denotes missing data with a “.” or anything else other than “NA.” The problem is that even though R typically orders factors in alphabetical or numerical order, it is possible to create a mismatch between the actual number and the order in the levels. Here are some code examples. Firstly, where a number is treated as a character. hmm &lt;- rep(c(4, &quot;0&quot;, 2, 5, 3, 1), 3) hmm ## [1] &quot;4&quot; &quot;0&quot; &quot;2&quot; &quot;5&quot; &quot;3&quot; &quot;1&quot; &quot;4&quot; &quot;0&quot; &quot;2&quot; &quot;5&quot; &quot;3&quot; &quot;1&quot; &quot;4&quot; &quot;0&quot; &quot;2&quot; &quot;5&quot; &quot;3&quot; ## [18] &quot;1&quot; class(hmm) ## [1] &quot;character&quot; In this case the vector is class character, but if we’d read it in from a file it would likely have been made a factor. Let’s see what happens when we coerce it to factor: as.factor(hmm) ## [1] 4 0 2 5 3 1 4 0 2 5 3 1 4 0 2 5 3 1 ## Levels: 0 1 2 3 4 5 Seems ok? What if we try to coerce that factor to a number? as.numeric(as.factor(hmm)) ## [1] 5 1 3 6 4 2 5 1 3 6 4 2 5 1 3 6 4 2 Ouch! While the level labels start at 0, the numeric representation of the levels start at 1, so coercing them to numbers creates a mismatch… If you need to fix this, you should always coerce to character first. as.numeric(as.character(as.factor(hmm))) ## [1] 4 0 2 5 3 1 4 0 2 5 3 1 4 0 2 5 3 1 What about if we insert a character instead of a number, like “O” instead of “0” hmm2 &lt;- rep(c(4, &quot;O&quot;, 2, 5, 3, 1), 3) hmm2 ## [1] &quot;4&quot; &quot;O&quot; &quot;2&quot; &quot;5&quot; &quot;3&quot; &quot;1&quot; &quot;4&quot; &quot;O&quot; &quot;2&quot; &quot;5&quot; &quot;3&quot; &quot;1&quot; &quot;4&quot; &quot;O&quot; &quot;2&quot; &quot;5&quot; &quot;3&quot; ## [18] &quot;1&quot; class(hmm2) ## [1] &quot;character&quot; as.factor(hmm2) ## [1] 4 O 2 5 3 1 4 O 2 5 3 1 4 O 2 5 3 1 ## Levels: 1 2 3 4 5 O Interesting, the “O” is not the 6th level, not the first… What if we coerce to numeric? as.numeric(as.factor(hmm2)) ## [1] 4 6 2 5 3 1 4 6 2 5 3 1 4 6 2 5 3 1 Oops!!! Converting all your zeroes to sixes is really going to mess with your results!!! And if we try our as.character fix? as.numeric(as.character(as.factor(hmm2))) ## Warning: NAs introduced by coercion ## [1] 4 NA 2 5 3 1 4 NA 2 5 3 1 4 NA 2 5 3 1 R doesn’t know what to do with the Os, so it makes them NA and gives you a warning. Watch out for this, because ignoring the warning and leaving out zero values could seriously bias your results! 6.6 A quick aside on data structures R’s basic data structures include the vector, list, matrix, data frame, and factors References "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
